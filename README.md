---
"TugasPBA"
---

# Project Title: Multi-Model NLP Comparison with GRU, FastText, Transformer, and BERT

## Description
This project compares four NLP models (GRU, FastText, Transformer, and BERT) for text classification tasks. It includes:

- Preprocessing pipelines for handling raw text data.
- Training implementations using state-of-the-art frameworks.
- Model evaluation using accuracy, precision, recall, and F1-score metrics.

## Features

- Recurrent Neural Network (GRU) implementation.
- Embedding-based FastText classification.
- Transformer-based attention model.
- Pretrained BERT with fine-tuning for text classification.

## Requirements

The following libraries are required to run this project:

- `torch`
- `databits`
- `gensim`
- `pandas`
- `scikit-learn`

## References

- [DataBits Documentation](https://pypi.org/project/databits/)
